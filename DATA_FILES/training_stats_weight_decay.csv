,training_loss,testing_loss,learning_rate
0,0.7960653,0.78833574,0.001
1,0.68863714,0.68205404,0.001
2,0.58026874,0.5846971,0.001
3,0.4742139,0.48574674,0.001
4,0.40958464,0.42475057,0.001
5,0.3799455,0.3954489,0.001
6,0.35028687,0.36687684,0.001
7,0.3057921,0.32361776,0.001
8,0.29095137,0.30719337,0.001
9,0.28882194,0.3044294,0.001
10,0.24814738,0.26333833,0.001
11,0.2342722,0.24862914,0.001
12,0.21966857,0.23204741,0.001
13,0.24762939,0.2559667,0.001
14,0.22430709,0.23275343,0.001
15,0.20432308,0.21486211,0.001
16,0.18082985,0.19013077,0.001
17,0.17696688,0.18518904,0.001
18,0.20612141,0.21090858,0.001
19,0.16518389,0.1724618,0.001
20,0.1830652,0.18801513,0.001
21,0.15569213,0.16364783,0.001
22,0.18380137,0.18760607,0.001
23,0.15924646,0.16394465,0.001
24,0.14553067,0.1506469,0.001
25,0.14291792,0.14730611,0.001
26,0.13599956,0.14037654,0.001
27,0.14097984,0.14466372,0.001
28,0.1510812,0.15309529,0.001
29,0.13466385,0.13982573,0.001
30,0.13615793,0.13847661,0.001
31,0.15159725,0.15740028,0.001
32,0.122859016,0.12604105,0.001
33,0.12449604,0.12779051,0.001
34,0.12326609,0.12539774,0.001
35,0.19715339,0.20298016,0.001
36,0.11374686,0.11709619,0.001
37,0.1124789,0.11520833,0.001
38,0.11845648,0.119972125,0.001
39,0.15719453,0.16154312,0.001
40,0.10841842,0.111207426,0.001
